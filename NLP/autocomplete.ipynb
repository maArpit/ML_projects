{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nimport math\nimport nltk\nimport re\nfrom collections import defaultdict\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/twitter/en_US.twitter.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"with open(\"../input/twitter/en_US.twitter.txt\", \"r\") as f:\n    data = f.read()\nprint(type(data))","execution_count":2,"outputs":[{"output_type":"stream","text":"<class 'str'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_vocab(sentences, min_freq):\n    vocab = []\n    word_count = defaultdict(int)\n    for sentence in sentences:\n        for word in sentence:\n            word_count[word] += 1\n    for word, cnt in word_count.items():\n        if cnt >= min_freq:\n            vocab.append(word)\n    return vocab\n\ndef replace_oov_with_unk(sentences, vocab, unknown_word='<UNK>'):\n    return [[word if word in vocab else unknown_word for word in sentence] for sentence in sentences]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(data, min_freq):\n    sentences = data.split(\"\\n\")\n    sentences = [s.strip() for s in sentences]\n    sentences = [s for s in sentences if len(s) > 0]\n    tokenized_sentences = [nltk.word_tokenize(s.lower()) for s in sentences]\n    n_sentences = len(tokenized_sentences)\n    train_size = int(n_sentences * 0.8)\n    train_data, test_data = tokenized_sentences[:train_size], tokenized_sentences[train_size:]\n    vocab = build_vocab(train_data, min_freq)\n    train_data = replace_oov_with_unk(train_data, vocab)\n    test_data = replace_oov_with_unk(test_data, vocab)\n    return train_data, test_data, vocab","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cal_n_gram_counts(data, n, start=\"<s>\", end=\"<e>\"):\n    n_grams = defaultdict(int)\n    for sentence in data:\n        sentence = [start] * n + sentence + [end]\n        sentence = tuple(sentence)\n        for i in range(len(sentence)):\n            n_gram = sentence[i:i + n]\n            n_grams[n_gram] += 1\n    return n_grams","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def estimate_probability(word, n_gram, n_grams, np1_grams, vocab_size, k=1):\n    n_gram = tuple(n_gram)\n    np1_gram = n_gram + (word,)\n    return (np1_grams[np1_gram] + k) / (n_grams[n_gram] + vocab_size * k)\n\ndef estimate_probabilities(n_gram, n_grams, np1_grams, vocab, k=1):\n    vocab = vocab + [\"<e>\", \"<UNK>\"]\n    vocab_size =  len(vocab)\n    probabilities = {}\n    for word in vocab:\n        probabilities[word] = estimate_probability(word, n_gram, n_grams, np1_grams, vocab_size, k)\n    return probabilities\n\ndef next_word(prev_tokens, n_grams, np1_grams, vocab, k=1):\n    n = len(list(n_grams.keys())[0])\n    n_gram = prev_tokens[-n:]\n    probs = estimate_probabilities(n_gram, n_grams, np1_grams, vocab, k)\n    max_prob = max(probs.values())\n    for k, v in probs.items():\n        if v == max_prob: \n            return k","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data, vocab = preprocess(data[:10000000], 1)\nprint(len(train_data), len(vocab))\nn_grams, np1_grams = cal_n_gram_counts(train_data, 3), cal_n_gram_counts(train_data, 4)","execution_count":7,"outputs":[{"output_type":"stream","text":"115056 73658\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = [\"what\", \"are\", \"you\"]\nfor i in range(100):\n    nw = next_word(s, n_grams, np1_grams, vocab, 3)\n    s.append(nw)\n    if nw == '<e>':\n        break\nprint(s)","execution_count":11,"outputs":[{"output_type":"stream","text":"['what', 'are', 'you', 'doing', '?', '<e>']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}